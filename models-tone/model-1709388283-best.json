{"learning_rate": 0.004676149959854764, "net_arch": {"pi": [104, 237], "vf": [833, 472, 499, 755, 160]}, "net_arch_dqn": [95, 532, 762], "batch_size": 256, "model_name": "model-1709388283", "map_size": [10, 10], "reset": 157, "box_near_goal": 0.48606131963976396, "box_close_goal": 0.037483701235590305, "box_move_reward": -0.23916238323978378, "box_goal_reward": 0.8015933512535827, "box_player_reward": 0.9505601763012552, "final_player_reward": -0.49514229847172575, "preform_step": 0.9153181393517456, "win_reward": 137, "invalid_move_reward": -1.7850313782123237, "max_invalid_move_reset": 12, "model_type": "PPO", "policy": "MlpPolicy", "folder_path_for_models": "models-tone", "model_performance": 0}