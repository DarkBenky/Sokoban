{"learning_rate": 0.049168003553058615, "net_arch": {"pi": [732, 142], "vf": [370, 473, 519]}, "net_arch_dqn": [925, 245, 838, 563, 987], "batch_size": 32, "model_name": "model-1709666763", "map_size": [10, 10], "reset": 176, "box_near_goal": 0.8821521266840802, "box_close_goal": 0.491559001108113, "box_move_reward": 0.6152564291114184, "box_goal_reward": 0.20445624435286636, "box_player_reward": 0.31445475017463087, "final_player_reward": 0.7455601680223913, "preform_step": 0.07092473687153245, "win_reward": 91, "invalid_move_reward": -1.245382909063963, "no_win_reward": -15.081460954946039, "model_type": "PPO", "policy": "MlpPolicy", "folder_path_for_models": "models-tone", "model_performance": 0}