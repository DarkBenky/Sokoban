{"learning_rate": 0.016630944586734385, "net_arch": {"pi": [274, 672, 996, 988], "vf": [314, 105, 866]}, "net_arch_dqn": [904, 229, 905, 583], "batch_size": 128, "model_name": "model-1709427698", "map_size": [10, 10], "reset": 101, "box_near_goal": 0.45044983963379814, "box_close_goal": 0.5314927277278894, "box_move_reward": -0.33455482833906625, "box_goal_reward": -0.10507896877304645, "box_player_reward": 0.3885509730936374, "final_player_reward": -0.46873146461000514, "preform_step": -0.6422737492859105, "win_reward": 186, "invalid_move_reward": -12.645668661611767, "max_invalid_move_reset": 10, "model_type": "PPO", "policy": "MlpPolicy", "folder_path_for_models": "models-tone", "model_performance": 0}