{"learning_rate": 0.03376253210378088, "net_arch": {"pi": [687, 168, 328, 690, 1005], "vf": [659, 540, 522, 991, 988]}, "net_arch_dqn": [239, 654, 637, 329], "batch_size": 32, "model_name": "model-1709655961", "map_size": [10, 10], "reset": 195, "box_near_goal": 0.8504006865825935, "box_close_goal": 0.4589327170610149, "box_move_reward": 0.2640225013839781, "box_goal_reward": -0.17419626462260074, "box_player_reward": 0.42029277242985863, "final_player_reward": 0.7755425264036127, "preform_step": 0.7714959703312492, "win_reward": 75, "invalid_move_reward": -10.378110100680203, "no_win_reward": -9.692047792538753, "model_type": "PPO", "policy": "MlpPolicy", "folder_path_for_models": "models-tone", "model_performance": 0}