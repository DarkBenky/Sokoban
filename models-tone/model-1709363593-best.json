{"learning_rate": 0.012426905070377485, "net_arch": {"pi": [593, 606, 980, 549, 1001], "vf": [601, 674, 580]}, "net_arch_dqn": [730, 186], "batch_size": 32, "model_name": "model-1709363593", "map_size": [10, 10], "reset": 112, "box_near_goal": 0.9931495174161321, "box_close_goal": 0.6815115793434516, "box_move_reward": -0.3359831936978861, "box_goal_reward": 0.4826995659255442, "box_player_reward": -0.859609860786464, "final_player_reward": 0.6550133523947606, "preform_step": 0.02899632006717856, "win_reward": 64, "invalid_move_reward": -2.748213743873926, "max_invalid_move_reset": 15, "model_type": "PPO", "policy": "MlpPolicy", "folder_path_for_models": "models-tone", "model_performance": 0}