{"learning_rate": 0.07522710722051361, "net_arch": {"pi": [581], "vf": [824, 899, 917]}, "net_arch_dqn": [785, 463, 241, 402, 981], "batch_size": 128, "model_name": "model-1709641267", "map_size": [10, 10], "reset": 92, "box_near_goal": 0.44784484565036886, "box_close_goal": 0.6170663668707914, "box_move_reward": -0.23180387194148833, "box_goal_reward": 0.9859436369227714, "box_player_reward": -0.7103579259283495, "final_player_reward": -0.7479785519227828, "preform_step": -0.3315980973779129, "win_reward": 139, "invalid_move_reward": -10.728540928000939, "no_win_reward": -17.117355947694627, "model_type": "PPO", "policy": "MlpPolicy", "folder_path_for_models": "models-tone", "model_performance": 0}