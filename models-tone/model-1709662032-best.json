{"learning_rate": 0.03583261461399176, "net_arch": {"pi": [621, 88, 445, 1011, 862], "vf": [936, 273, 749]}, "net_arch_dqn": [289, 419], "batch_size": 64, "model_name": "model-1709662032", "map_size": [10, 10], "reset": 68, "box_near_goal": 0.30508043440322796, "box_close_goal": 0.5800399957043205, "box_move_reward": 0.14355999571793832, "box_goal_reward": 0.33465665972573255, "box_player_reward": -0.2878855652796859, "final_player_reward": -0.7209036383558742, "preform_step": -0.885267488300634, "win_reward": 160, "invalid_move_reward": -8.366515936674055, "no_win_reward": -5.500272980001927, "model_type": "PPO", "policy": "MlpPolicy", "folder_path_for_models": "models-tone", "model_performance": 0}