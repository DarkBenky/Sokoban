{"learning_rate": 0.027416406692044582, "net_arch": {"pi": [979, 815, 456, 98, 496], "vf": [992, 676, 998, 542]}, "net_arch_dqn": [173], "batch_size": 256, "model_name": "model-1709663243", "map_size": [10, 10], "reset": 184, "box_near_goal": 0.7645492195398897, "box_close_goal": 0.05003157400253533, "box_move_reward": -0.0998495413320657, "box_goal_reward": 0.8973047691258107, "box_player_reward": 0.8939871038484368, "final_player_reward": -0.6971936314888221, "preform_step": 0.40094691253442094, "win_reward": 98, "invalid_move_reward": -10.252501029632935, "no_win_reward": -14.430698210241417, "model_type": "PPO", "policy": "MlpPolicy", "folder_path_for_models": "models-tone", "model_performance": 0}