{"learning_rate": 0.04441085078116746, "net_arch": {"pi": [544, 725, 846, 452, 107], "vf": [178, 222, 556]}, "net_arch_dqn": [319, 815, 375, 114, 608], "batch_size": 128, "model_name": "model-1709650693", "map_size": [10, 10], "reset": 200, "box_near_goal": 0.8492100758279001, "box_close_goal": 0.1910438655085156, "box_move_reward": 0.5776504034404351, "box_goal_reward": 0.6921070556981634, "box_player_reward": 0.15534393939965585, "final_player_reward": 0.07904842243057097, "preform_step": 0.1623183219364308, "win_reward": 144, "invalid_move_reward": -11.435579000164013, "no_win_reward": -11.744091795325202, "model_type": "PPO", "policy": "MlpPolicy", "folder_path_for_models": "models-tone", "model_performance": 0}